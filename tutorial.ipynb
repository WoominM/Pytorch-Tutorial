{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bea55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchlight import DictAction\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import yaml\n",
    "import csv\n",
    "import traceback\n",
    "import thop\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import model\n",
    "from CustomDataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035af428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    torch.cuda.manual_seed_all(seed) # gpu固定\n",
    "    torch.manual_seed(seed) # cpu固定\n",
    "    np.random.seed(seed) # numpy固定\n",
    "    random.seed(seed) # python固定\n",
    "    torch.backends.cudnn.deterministic = True # 找出最优的卷积算法，保证复现性\n",
    "    torch.backends.cudnn.benchmark = False # cudnn加速，网络结构固定时才有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38525553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Unsupported value encountered.')\n",
    "        \n",
    "def import_class(import_str):\n",
    "    mod_str, _sep, class_str = import_str.rpartition('.')\n",
    "    __import__(mod_str)\n",
    "    try:\n",
    "        return getattr(sys.modules[mod_str], class_str)\n",
    "    except AttributeError:\n",
    "        raise ImportError('Class %s cannot be found (%s)' % (class_str, traceback.format_exception(*sys.exc_info())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d203c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Pytorch Tutorial')\n",
    "    \n",
    "    # directory\n",
    "    parser.add_argument('--work-dir', \n",
    "                        default='./...',\n",
    "                        help='the work folder for storing log')\n",
    "    parser.add_argument('--save-dir', \n",
    "                        default='./...',\n",
    "                        help='the work folder for storing results')\n",
    "    parser.add_argument('--config', \n",
    "                        default='./config.yaml',\n",
    "                        help='path to the configuration file')\n",
    "\n",
    "    # train or test\n",
    "    parser.add_argument('--phase', \n",
    "                        default='train', \n",
    "                        help='must be train or test')\n",
    "    \n",
    "    # feeder\n",
    "    parser.add_argument('--num-worker',\n",
    "                        type=int, default=8,\n",
    "                        help='the number of worker for data loader')\n",
    "    parser.add_argument('--use-mnist',\n",
    "                        type=str2bool, default=True,\n",
    "                        help='using MNIST Dataset for training or not')\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--model', \n",
    "                        default=None, \n",
    "                        help='the model will be used')\n",
    "    parser.add_argument('--model-args',\n",
    "                        action=DictAction, default=dict(),\n",
    "                        help='the arguments of model')\n",
    "    parser.add_argument('--weights',\n",
    "                        default=None,\n",
    "                        help='the weights for network initialization')\n",
    "\n",
    "    # optim\n",
    "    parser.add_argument('--lr', \n",
    "                        type=float, default=0.01, \n",
    "                        help='initial learning rate')\n",
    "    parser.add_argument('--step',\n",
    "                        type=int, default=[20, 40, 60], nargs='+',\n",
    "                        help='the epoch where optimizer reduce the learning rate')\n",
    "    parser.add_argument('--device',\n",
    "                        type=int, default=0, nargs='+',\n",
    "                        help='the indexes of GPUs for training or testing')\n",
    "    parser.add_argument('--optimizer', \n",
    "                        default='SGD', \n",
    "                        help='type of optimizer')\n",
    "    parser.add_argument('--nesterov', \n",
    "                        type=str2bool, default=False, \n",
    "                        help='use nesterov or not')\n",
    "    parser.add_argument('--batch-size', \n",
    "                        type=int, default=256, \n",
    "                        help='training batch size')\n",
    "    parser.add_argument('--test-batch-size', \n",
    "                        type=int, default=256, \n",
    "                        help='test batch size')\n",
    "    parser.add_argument('--start-epoch',\n",
    "                        type=int, default=0,\n",
    "                        help='start training from which epoch')\n",
    "    parser.add_argument('--num-epoch',\n",
    "                        type=int, default=80,\n",
    "                        help='stop training in which epoch')\n",
    "    parser.add_argument('--weight-decay',\n",
    "                        type=float, default=0.0005,\n",
    "                        help='weight decay for optimizer')\n",
    "    parser.add_argument('--warm_up_epoch', \n",
    "                        type=int, default=0,\n",
    "                        help='warm up strategy')\n",
    "    \n",
    "     # etc \n",
    "    parser.add_argument('--seed',\n",
    "                        type=int, default=0, \n",
    "                        help='random seed for pytorch')\n",
    "    parser.add_argument('--save-interval',\n",
    "                        type=int, default=5,\n",
    "                        help='the interval for storing models (#iteration)')\n",
    "    parser.add_argument('--save-epoch',\n",
    "                        type=int, default=0,\n",
    "                        help='the start epoch to save model (#iteration)')\n",
    "    parser.add_argument('--eval-interval',\n",
    "                        type=int, default=5,\n",
    "                        help='the interval for evaluating models (#iteration)')\n",
    "    parser.add_argument('--print-log',\n",
    "                        type=str2bool, default=True,\n",
    "                        help='print logging or not')\n",
    "\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dec330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.load_data()\n",
    "        self.load_model()\n",
    "        self.load_optimizer()\n",
    "        \n",
    "        dataiter = iter(self.data_loader[self.args.phase])\n",
    "        self.lr = self.args.lr\n",
    "        self.best_acc = 0\n",
    "        self.best_acc_epoch = 0\n",
    "        \n",
    "        self.model = self.model.cuda(self.output_device)\n",
    "        if type(self.args.device) is list:\n",
    "            if len(self.args.device) > 1:\n",
    "                self.model = nn.DataParallel(\n",
    "                    self.model,\n",
    "                    device_ids=self.args.device,\n",
    "                    output_device=self.output_device)     \n",
    "\n",
    "    def load_data(self):\n",
    "        self.data_loader = dict()\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "        ])\n",
    "        if self.args.phase == 'train':\n",
    "            self.train_set = datasets.MNIST(root='./mnist', train=True, transform=transform, download=True) if self.args.use_mnist \\\n",
    "            else CustomDataset()\n",
    "            self.data_loader['train'] = torch.utils.data.DataLoader(\n",
    "                dataset=self.train_set,\n",
    "                batch_size=self.args.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers = self.args.num_worker,\n",
    "                worker_init_fn=init_seed)\n",
    "\n",
    "        self.test_set = datasets.MNIST(root='./mnist', train=False, transform=transform, download=True)  if self.args.use_mnist \\\n",
    "        else CustomDataset()  \n",
    "        self.data_loader['test'] = torch.utils.data.DataLoader(\n",
    "            dataset=self.test_set,\n",
    "            batch_size=self.args.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers = self.args.num_worker,\n",
    "            worker_init_fn=init_seed)\n",
    "    \n",
    "    def load_model(self):\n",
    "        output_device = self.args.device[0] if type(self.args.device) is list else self.args.device\n",
    "        self.output_device = output_device\n",
    "        model = import_class(self.args.model)\n",
    "        self.model = model(**self.args.model_args)\n",
    "        self.loss = nn.CrossEntropyLoss().cuda(output_device)\n",
    "        \n",
    "        self.data_shape = [1,28,28] if self.args.use_mnist else self.train_set.getshape() \n",
    "        inputsample = torch.rand([1,1] + self.data_shape)\n",
    "        self.flops, self.params = thop.profile(deepcopy(self.model), inputs=inputsample, verbose=False)\n",
    "        \n",
    "        if self.args.weights:\n",
    "            weights = torch.load(self.args.weights)\n",
    "            weights = OrderedDict([[k.split('module.')[-1], v.cuda(output_device)] for k, v in weights.items()])\n",
    "            self.model.load_state_dict(weights)\n",
    "            \n",
    "    def load_optimizer(self):\n",
    "        if self.args.optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.args.lr,\n",
    "                momentum=0.9,\n",
    "                nesterov=self.args.nesterov,\n",
    "                weight_decay=self.args.weight_decay)\n",
    "        elif self.args.optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.args.lr,\n",
    "                weight_decay=self.args.weight_decay)\n",
    "        else:\n",
    "            raise ValueError()        \n",
    "        \n",
    "    def adjust_learning_rate(self, epoch):\n",
    "        if self.args.optimizer == 'SGD' or self.args.optimizer == 'Adam':\n",
    "            if epoch < self.args.warm_up_epoch:\n",
    "                lr = self.args.lr * (epoch + 1) / self.args.warm_up_epoch\n",
    "            else:\n",
    "                lr = self.args.lr * (0.1 ** np.sum(epoch >= np.array(self.args.step)))\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            return lr\n",
    "        else:\n",
    "            raise ValueError()    \n",
    "            \n",
    "    def print_log(self, str, print_time=False):\n",
    "        if print_time:\n",
    "            localtime = time.asctime(time.localtime(time.time()))\n",
    "            str = \"[ \" + localtime + ' ] ' + str\n",
    "        print(str)\n",
    "        if self.args.print_log:\n",
    "            with open('{}/log.txt'.format(self.args.work_dir), 'a') as f:\n",
    "                print(str, file=f)\n",
    "                \n",
    "    def train(self, epoch, save_model=True):\n",
    "        self.model.train()\n",
    "        self.print_log('Training epoch: {}'.format(epoch + 1))\n",
    "        train_loader = self.data_loader['train']\n",
    "#         process = tqdm(train_loader, dynamic_ncols=True)\n",
    "        process = tqdm(train_loader, ncols=100)\n",
    "        self.adjust_learning_rate(epoch)\n",
    "        \n",
    "        loss_ = []\n",
    "        acc_ = []\n",
    "        for batch_idx, (data, label) in enumerate(process):\n",
    "            with torch.no_grad():\n",
    "                data, label = data.cuda(self.output_device), label.cuda(self.output_device)\n",
    "            data, label = Variable(data), Variable(label)\n",
    "\n",
    "            output = self.model(data)\n",
    "            loss = self.loss(output, label)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()    \n",
    "            \n",
    "            loss_.append(loss.data.item())\n",
    "            value, predicted_label = output.data.max(dim=1)\n",
    "            acc = torch.mean((predicted_label == label.data).float())\n",
    "            acc_.append(acc.data.item())\n",
    "            \n",
    "            self.lr = self.optimizer.param_groups[0]['lr']\n",
    "            process.set_description('Loss: {:.4f}, LR: {:.4f}'.format(loss.data.item(), self.lr))\n",
    "        \n",
    "        self.print_log('\\tMean training loss: {:.4f}.  Mean training acc: {:.2f}%.'.format(np.mean(loss_), np.mean(acc_)*100))\n",
    "        \n",
    "        if save_model and epoch%self.args.save_interval==0:\n",
    "            state_dict = self.model.state_dict()\n",
    "            weights = OrderedDict([[k.split('module.')[-1], v.cpu()] for k, v in state_dict.items()])\n",
    "            torch.save(weights, self.args.save_dir + '/epoch_' + str(epoch+1) + '.pt')\n",
    "        \n",
    "    \n",
    "    def evaluate(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.print_log('Eval epoch: {}'.format(epoch + 1))\n",
    "        test_loader = self.data_loader['test']\n",
    "        loss_ = []\n",
    "        acc_ = []\n",
    "        label_list = []\n",
    "        pred_list = []\n",
    "#         process = tqdm(test_loader, dynamic_ncols=True)\n",
    "        process = tqdm(test_loader, ncols=100)\n",
    "        \n",
    "        for batch_idx, (data, label) in enumerate(process):\n",
    "            label_list.append(label)\n",
    "            with torch.no_grad():\n",
    "                data, label = data.cuda(self.output_device), label.cuda(self.output_device)\n",
    "            data, label = Variable(data), Variable(label)\n",
    "            \n",
    "            output = self.model(data)\n",
    "            loss = self.loss(output, label)\n",
    "            \n",
    "            loss_.append(loss.data.item())\n",
    "            _, predicted_label = torch.max(output.data, 1)\n",
    "            acc = torch.mean((predicted_label == label.data).float())\n",
    "            acc_.append(acc.data.item())\n",
    "            pred_list.append(predicted_label.data.cpu().numpy())\n",
    "                        \n",
    "        loss = np.mean(loss_)\n",
    "        accuracy = np.mean(acc_)*100\n",
    "        if accuracy > self.best_acc:\n",
    "            self.best_acc = accuracy\n",
    "            self.best_acc_epoch = epoch + 1        \n",
    "        self.print_log('\\tMean test loss: {:.4f}.  Mean test acc: {:.2f}%.'.format(loss, accuracy))\n",
    "        \n",
    "        label_list = np.concatenate(label_list)\n",
    "        pred_list = np.concatenate(pred_list)\n",
    "        confusion = confusion_matrix(label_list, pred_list)\n",
    "        list_diag = np.diag(confusion)\n",
    "        list_raw_sum = np.sum(confusion, axis=1)\n",
    "        each_acc = list_diag / list_raw_sum\n",
    "        with open('{}/epoch{}_{}_each_class_acc.csv'.format(self.args.save_dir, epoch + 1, ['test']), 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(each_acc)\n",
    "            writer.writerows(confusion)\n",
    "            \n",
    "        \n",
    "    def start(self):\n",
    "        if self.args.phase == 'train':\n",
    "            self.print_log('Device: {}'.format(self.args.device if torch.cuda.is_available() else 'cpu')) \n",
    "            self.print_log('Model profile: {:.2f}G FLOPs and {:.2f}M Parameters'.format(self.flops / 1e9, self.params / 1e6))\n",
    "            self.print_log('Pretrained weights: {}'.format('True' if self.args.weights else 'False'))\n",
    "            self.print_log('Start epoch: {}'.format(self.args.start_epoch))\n",
    "            \n",
    "            self.print_log('\\nStart Training...')\n",
    "            \n",
    "        \n",
    "            for epoch in range(self.args.start_epoch, self.args.num_epoch):\n",
    "                self.print_log('*'*100)\n",
    "                self.train(epoch)\n",
    "                if epoch % 5 == 0:\n",
    "                    self.evaluate(epoch)\n",
    "                self.print_log('Best_Accuracy: {:.2f}%, epoch: {}'.format(self.best_acc, self.best_acc_epoch))\n",
    "\n",
    "            self.print_log('\\nFinishi Training!')\n",
    "            self.print_log('Best accuracy: {}'.format(self.best_acc))\n",
    "            self.print_log('Epoch number: {}'.format(self.best_acc_epoch))\n",
    "            self.print_log('Model name: {}'.format(self.args.work_dir))\n",
    "            self.print_log('Model profile: {:.2f}G FLOPs and {:.2f}M Parameters'.format(self.flops / 1e9, self.params / 1e6))\n",
    "            self.print_log('Weight decay: {}'.format(self.args.weight_decay))\n",
    "            self.print_log('Base LR: {}'.format(self.args.lr))\n",
    "            self.print_log('Batch Size: {}'.format(self.args.batch_size))\n",
    "            self.print_log('Test Batch Size: {}'.format(self.args.test_batch_size))\n",
    "            self.print_log('seed: {}'.format(self.args.seed))\n",
    "        \n",
    "        elif self.args.phase == 'test':\n",
    "            if self.args.weights is None:\n",
    "                raise ValueError('Please appoint --weights.')\n",
    "            self.args.print_log = False\n",
    "            self.print_log('Model:   {}.'.format(self.args.model))\n",
    "            self.print_log('Weights: {}.'.format(self.args.weights))\n",
    "            self.evaluate(epoch=0)\n",
    "            self.print_log('Done.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42e7f36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: [0]\n",
      "Model profile: 0.01G FLOPs and 0.01M Parameters\n",
      "Pretrained weights: False\n",
      "Start epoch: 0\n",
      "\n",
      "Start Training...\n",
      "****************************************************************************************************\n",
      "Training epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3029, LR: 0.0200: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3026.  Mean training acc: 7.03%.\n",
      "Eval epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean test loss: 2.3009.  Mean test acc: 12.50%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3052, LR: 0.0400: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3024.  Mean training acc: 6.25%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3019, LR: 0.0600: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3021.  Mean training acc: 10.94%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3010, LR: 0.0800: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3016.  Mean training acc: 10.94%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3023, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3007.  Mean training acc: 10.94%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3014, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.3000.  Mean training acc: 10.94%.\n",
      "Eval epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean test loss: 2.2999.  Mean test acc: 12.50%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3013, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2987.  Mean training acc: 10.94%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2961, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2978.  Mean training acc: 13.28%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2960, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2968.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2921, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2962.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2952, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2948.  Mean training acc: 14.06%.\n",
      "Eval epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean test loss: 2.2983.  Mean test acc: 11.72%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2966, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2942.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2977, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2931.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2939, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2924.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2922, LR: 0.1000: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2916.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2903, LR: 0.0100: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2911.  Mean training acc: 14.06%.\n",
      "Eval epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean test loss: 2.2968.  Mean test acc: 11.72%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3091, LR: 0.0100: 100%|███████████████████████████████████████| 2/2 [00:00<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2911.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2958, LR: 0.0100: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2910.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2808, LR: 0.0100: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2909.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "****************************************************************************************************\n",
      "Training epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2988, LR: 0.0100: 100%|███████████████████████████████████████| 2/2 [00:00<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean training loss: 2.2909.  Mean training acc: 14.06%.\n",
      "Best_Accuracy: 12.50%, epoch: 1\n",
      "\n",
      "Finishi Training!\n",
      "Best accuracy: 12.5\n",
      "Epoch number: 1\n",
      "Model name: ./\n",
      "Model total number of params: 9890\n",
      "Weight decay: 0.0004\n",
      "Base LR: 0.1\n",
      "Batch Size: 64\n",
      "Test Batch Size: 64\n",
      "seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = get_parser()\n",
    "    os.chdir(os.getcwd())\n",
    "    p = parser.parse_args(args=[])\n",
    "#     p = parser.parse_args()\n",
    "    if p.config is not None:\n",
    "        with open(p.config, 'r') as f:\n",
    "            default_arg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        key = vars(p).keys()\n",
    "        for k in default_arg.keys():\n",
    "            if k not in key:\n",
    "                print('WRONG ARG: {}'.format(k))\n",
    "                assert (k in key)\n",
    "        parser.set_defaults(**default_arg)\n",
    "\n",
    "#     arg = parser.parse_args()\n",
    "    args = parser.parse_args(args=[])\n",
    "#     args.phase = 'test'\n",
    "#     args.weights = args.save_dir + '/epoch_16.pt'\n",
    "#     args.work_dir = args.work_dir + '/'\n",
    "#     args.start_epoch=100\n",
    "    \n",
    "    init_seed(args.seed)\n",
    "    processor = Processor(args) \n",
    "    processor.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
